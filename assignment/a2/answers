# Write your short answers in this file, replacing the placeholders as appropriate.
# This assignment consists of 1 parts for a total of 70 points.
# For numerical answers, copy and paste at least 5 significant figures.
# - Neural Network Text Classification (70 points)



###################################################################
###################################################################
## Neural Network Text Classification (70 points)
###################################################################
###################################################################


# ------------------------------------------------------------------
# | Section (2): Classification with various Word2Vec-based Models (2 points)  | 
# ------------------------------------------------------------------

# Question 2.a (/1): What is the percentage of positive examples in the training set (e.g. 72.575% is 0.72575)?
neural_network_text_classification_2_2_a: 
- 49.845%

# Question 2.b (/1): What is the percentage of positive examples in the test set (e.g. 72.575% is 0.72575)?
neural_network_text_classification_2_2_b: 
- 50.26%


# ------------------------------------------------------------------
# | Section (2.1): The Role of Shuffling of the Training Set (6 points)  | 
# ------------------------------------------------------------------

# Question 2.1.a (/3): What is the highest validation accuracy that you observed after 10 epochs? (Copy and paste the decimal value e.g. a number like 0.5678 or 0.87654)
neural_network_text_classification_2_1_2_1_a: 0.5072

# Question 2.1.b (/3): What is the highest validation accuracy that you observed for the shuffled run after 10 epochs?
neural_network_text_classification_2_1_2_1_b: 0.8008


# ------------------------------------------------------------------
# | Section (2.2): DAN vs Weighted Averaging Models using Attention (17 points)  | 
# ------------------------------------------------------------------

# Question 2.2.1.a (/2): Calculate the context vector for the following query and key/value vectors.
neural_network_text_classification_2_2_2_2_1_a: [ 0.   0.5 -1. ]

# Question 2.2.1.b (/2): What are the weights for the key/value vectors?
neural_network_text_classification_2_2_2_2_1_b: [0.5 0.5]

# Question 2.2.2.a (/7): What is the highest validation accuracy that you observed for the wan training after 10 epochs? (Copy and paste the decimal value e.g. a number like 0.5678 or 0.87654)
neural_network_text_classification_2_2_2_2_2_a: 0.7648

# Question 2.2.2.b (/3): List the 5 most important words separated by commas. (Again, if a word appears twice, note it twice.)
neural_network_text_classification_2_2_2_2_2_b: [terrible, worst, great, simply, lured]

# Question 2.2.2.c (/3): List the 5 least important words separated by commas. (Again, if a word appears twice, note it twice.)
neural_network_text_classification_2_2_2_2_2_c: [be, be, an, This, this]


# ------------------------------------------------------------------
# | Section (2.3): Approaches for Training of Embeddings (9 points)  | 
# ------------------------------------------------------------------

# Question 2.3.a (/3): What is the highest validation accuracy that you observed for the static model after 10 epochs? (Copy and paste the decimal value e.g. a number like 0.5678 or 0.87654)
neural_network_text_classification_2_3_2_3_a: 0.7964

# Question 2.3.b (/3): What is the highest validation accuracy that you observed for the model where you initialized with word2vec vectors but allow them to retrain for 3 epochs? (Copy and paste the decimal value e.g. a number like 0.5678 or 0.87654)
neural_network_text_classification_2_3_2_3_b: 0.7796

# Question 2.3.c (/3): What is the highest validation accuracy that you observed for the model where you initialized randomly and then trained? (Copy and paste the decimal value e.g. a number like 0.5678 or 0.87654)
neural_network_text_classification_2_3_2_3_c: 0.7840


# ------------------------------------------------------------------
# | Section (3): Classification with BERT (36 points)  | 
# ------------------------------------------------------------------

# Question 3.1.a (/1): Why do the attention_masks have 4 and 1 zeros, respectively?
# (This question is multiple choice.  Delete all but the correct answer).
neural_network_text_classification_3_3_1_a: 
 - For the first example 4 positions are padded while for the second one it is only one.

# Question 3.1.b (/1): How many outputs are there?
neural_network_text_classification_3_3_1_b: 
- 2

# Question 3.1.c (/1): Which output do we need to use to get token-level embeddings?
# (This question is multiple choice.  Delete all but the correct answer).
neural_network_text_classification_3_3_1_c: 
 - the first

# Question 3.1.d (/2): Which input_id number corresponds to 'bank' in the two sentences?
neural_network_text_classification_3_3_1_d: 
- 3085

# Question 3.1.e (/2): Which token array index number corresponds to 'bank' in the first sentence?
neural_network_text_classification_3_3_1_e: 
- 2

# Question 3.1.f (/2): Which array index number corresponds to 'bank' in the second sentence?
neural_network_text_classification_3_3_1_f: 
- 4

# Question 3.1.g (/3): What is the cosine similarity between the BERT outputs for the two occurences of 'bank' in the two sentences?
neural_network_text_classification_3_3_1_g: 
- 0.74

# Question 3.1.h (/3): How does this relate to the cosine similarity of 'this' (sentence 1) and 'the' (sentence 2). Compute the cosine similarity.
neural_network_text_classification_3_3_1_h: 
- 0.81

# Question 3.2.a (/7): What is the highest validation accuracy that you observed for the BERT [CLS]-classification model after training for 2 epochs? (Copy and paste the decimal value e.g. a number like 0.5678 or 0.87654)
neural_network_text_classification_3_3_2_a: 0.8566

# Question 3.3.a (/7): What is the highest validation accuracy that you observed for the BERT-averaging-classification model after training for 2 epochs? (Copy and paste the decimal value e.g. a number like 0.5678 or 0.87654)
neural_network_text_classification_3_3_3_a: 0.8570

# Question 3.4.a (/7): What is the highest validation accuracy that you observed for the BERT-CNN-classification model after 2 epochs? (Copy and paste the decimal value e.g. a number like 0.5678 or 0.87654)
neural_network_text_classification_3_3_4_a: 0.4974
